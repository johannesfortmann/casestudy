---
title: "General_Tasks_Group_32"
author: "Johannes Pascal Falkhofen, Johannes Fortmann, Felix Remien, Georg Viktor von Usedom, Lennart Rathje"
date: "2023-02-17"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

Als erstes werden die benötigten Pakete installiert bzw. geladen.
## Library

```{r, message=FALSE }
if(!require("install.load")){
  install.packages("install.load")
}
library(install.load)

install_load("readr", "dplyr", "ggplot2", "plotly", "knitr", "modeest","diptest", "moments","tidyverse", "scales","nortest")
```


## Task 1

### Subtask a
Arbeits-Datensatz erstellen:
Zunächst muss ein arbeitsfähiger Datensatz erstellt werden, dafür werden zuerst alle nötigen Pakete installiert und geladen werden.

```{r, message=FALSE }
if(!require("install.load")){
  install.packages("install.load")
}
library(install.load)

install_load("readr", "dplyr", "ggplot2", "plotly", "knitr", "modeest","diptest", "moments","tidyverse", "scales","nortest")
```

Dann werden die beiden benötigten Dateien geladen. 

```{r }
Komponente_K7 <- read.csv2("Data/Logistikverzug/Komponente_K7.csv")
Logistikverzug_K7 <- read.csv("Data/Logistikverzug/Logistikverzug_K7.csv",sep=";")
```
Es fällt auf, dass sechs Komponenten fehlerhaft sind, dies spielt für den Arbeits-Datensatz jedoch keine Rolle, da diese trotzdem verschickt wurden und nur das für die zu bearbeitenden Aufgaben vorausgesetzt wird. Als Logistikverzug wird die Differenz zwischen Wareneingangsdatum und Versanddatum angenommen.Die Versanddaten sind nicht gegeben, allerdings geht  aus der Aufgabenstellung geht hervor, dass die Arbeiter einen Tag von Warenproduktion zu Warenversand an einem Werktag brauchen, bei Samstag brauchen sie zwei, da der Sonntag nur zur Produktion, aber nicht zum Versand genutzt wird. Um den echten Logistikverzug zu ermitteln, werden also zwei Tage bei einem Samstag und ein Tag bei allen anderen Tagen auf die Produktionsdaten addiert.

Die nötigen Daten aus den Tabellen werden unter Angabe ihrer IDNummer zusammengefügt.

```{r}
Logistikverzug <- merge(x = Komponente_K7[,c("IDNummer", "Produktionsdatum")], y = Logistikverzug_K7[ , c("IDNummer","Wareneingang")], by = "IDNummer")

```
Das Datumsformat aus Logistikverzug_K7 wird ins gleiche Format umgewandelt wie jenes aus Komponente_K7.
```{r}
Logistikverzug$Wareneingang <- as.Date(strptime(Logistikverzug$Wareneingang, format = "%d.%m.%Y"), format = "%Y-%m-%a")

```
Es wird eine zusätzliche Spalte erzeugt mit den Wochentagen.
```{r}
Logistikverzug$Wochentag = weekdays(as.Date(Logistikverzug$Produktionsdatum))
```
Es wird ein Tag extra auf den Wareneingang für alle Samstage addiert.
```{r}
samstagZeilen <- which(Logistikverzug$Wochentag == "Samstag")
Logistikverzug$Wareneingang[samstagZeilen] <- Logistikverzug$Wareneingang[samstagZeilen] +1

```
Nun wird für alle Differenzen zwischen Wareneingang und Produktionsdatum die Differenz um 1 vermindert. Somit werden für die Samstage nun zwei Tage berücksichtigt und für alle anderen Tage einer. 
```{r}
Logistikverzug$AdjustierterVerzug<-as.integer( as.Date(Logistikverzug$Wareneingang) - as.Date(Logistikverzug$Produktionsdatum)-1) 
```
```{r}
#hier werden noch Sachen removed
#rm(IDNummer)
```
Um den Logistikverzug darstellen zu können, wird zunächst ein statistischer Test durchgeführt, hier: Anderson-Darling-Test, der auch große Stichprobengrößen auf Normalverteilung prüfen kann.

```{r}
# Variable auswählen
var <- Logistikverzug$AdjustierterVerzug


ad.test(var)
```
Die Ausgabe des Anderson-Darling-Tests für die Variable "AdjustierterVerzug" gibt an, dass die Variable nicht normalverteilt ist. Das bedeutet, dass die Verteilung der Variable nicht der Normalverteilung entspricht. Der Test hat einen sehr kleinen p-Wert von weniger als 2,2e-16, was darauf hindeutet, dass die Nullhypothese der Normalverteilung abgelehnt werden sollte.

Durch die Verteilung der Daten ergibt sich, dass ein Boxplot eine nützliche Möglichkeit ist, um die Verteilung zu visualisieren, wenn die Variable nicht normalverteilt ist.
```{r}
boxplot(var, col = "blue", main = "Verteilung der Variable")
```
Da keine Normalverteilung vorliegt, wird nun auf Schiefe geprüft.
```{r}
skewness(var)
```

Eine Schiefe von 0,55 weist darauf hin, dass die Verteilung leicht rechtsschief (rechtssteil) ist, da die Schiefe positiv ist.


Zusätzlich wird auf Multimodalität geprüft, was im Folgenden der Hartigans' Dip-Test übernimmt.
```{r}
dip.test(var)
```
Die Ausgabe des Hartigans' Dip-Tests zeigt, dass der Dip-Statistikwert (D) 0,12326 beträgt und der p-Wert kleiner als 2,2e-16 ist. Da der p-Wert deutlich kleiner als das übliche Signifikanzniveau von 0,05 ist, können wir die Nullhypothese der Unimodalität ablehnen. Dies legt nahe, dass die Verteilung der Variablen möglicherweise nicht unimodal ist und mindestens bimodal sein könnte. Dies kann auf zwei unterschiedliche Paketdienstleister zurückzuführen sein, die verwendet werden. Es wäre sinnvoll, herauszufinden, ob dem so ist und welcher dann zu welchem Preis schneller liefert.

So eine bimodale rechtsschiefe Verteilung lässt sich sehr gut mit einem Densityplot darstellen, da man die Schiefe dort gut erkennen kann.
```{r}
# Dichteplot erstellen
densityplot <- density(var)
plot(densityplot, main = "Verteilung des Logistikverzuges",ylab = "Dichte")
```

Aufgrund des Plots scheint eine Bimodalität eher unwahrscheinlich. Tendenziell gibt es mehr kurze Verzögerungen, aber es gibt auch einige ungewöhnlich lange Verzögerungen, diese sollten vom Unternehmen weiter untersucht werden.
Einige wenige sehr große Ausreißer treiben das arithmetische Mittel hoch, diese treten jedoch selten auf, sodass davon auszugehen ist, dass sie durch höhere Umstände entstanden sind.


### Subtask b
Aufgabe b) Der minimale Verzug und der maximaler Verzug werden bestimmt.

```{r}
min(Logistikverzug$AdjustierterVerzug)
```
Der Minimalwert beträgt damit 1.
```{r}
max(Logistikverzug$AdjustierterVerzug)
```
Der Maximalwert beträgt damit 12.


### Subtask c
Der Mittelwert ist zu bestimmten und Alternativen dazu zu benennen.
```{r}
mean(Logistikverzug$AdjustierterVerzug)
```
Der Mittelwert beträgt damit 4.223554 Tage.

Neben dem ausreißeranfälligen arithmetischen Mittel gibt es noch den Median, dieser könnte ein geeigneteres Maß für die Zentralität der Verteilung sein, wenn die Verteilung rechtsschief ist. Je nach Schlussfolgerung, die aus den Daten gezogen werden soll, kann auch der Modus, also der am häufigsten vorkommende Wert in einer Datenmenge, sinnvoll sein. Ginge es darum, die Anzahl der Tage möglichst oft genau zu treffen, dann ist dieser Wert am relevantesten, geht es darum, möglichst oft in der Nähe des Wertes zu sein, dann ist es der Median und um sich ein Überblick zu verschaffen, reicht das arithmetische Mittel, ist allerdings aufgrund der Schiefe kritisch zu betrachten. 


```{r}
#hist(Logistikverzug$AdjustierterVerzug, breaks=10, main="Logistikverzug Histogramm", xlab="Logistikverzug (Tage)")
#y-Achse umbennen
# Histogramm erstellen und y-Achse umbenennen
#hist(Logistikverzug$AdjustierterVerzug, breaks=10, main="Logistikverzug Histogramm", xlab="Logistikverzug (Tage)", ylab="Häufigkeit")

```
### Subtask d
Für die schiefe Verteilung eignet sich ein Histogramm sehr gut, hier mit Plotly realisiert.
```{r}
# Histogramm erstellen
p <- plot_ly(Logistikverzug, x = ~AdjustierterVerzug, type = "histogram", nbinsx = 10)

# Layout anpassen
p <- p %>% layout(title = "Logistikverzug Histogram", xaxis = list(title = "Logistikverzug (days)"), yaxis = list(title = "Häufigkeit"))

# Histogramm anzeigen
p
```

## Task 2
Datenintegrität ist in relationalen Datenbanken gewährleistet, da sie Integritätsregeln wie Fremdschlüsselbeziehungen oder eindeutige Schlüssel unterstützen. Dies hilft, konsistente und widerspruchsfreie Daten zu erhalten, wodurch Fehler bei der Dateneingabe und Probleme bei der Datenanalyse vermieden werden.

In Bezug auf Skalierbarkeit erlauben relationale Datenbanken eine einfache Erweiterung, indem sie das Hinzufügen neuer Tabellen oder die Erweiterung bestehender Tabellen ermöglichen. So können neue Datensätze problemlos integriert werden, ohne dass die gesamte Datenbankstruktur geändert werden muss.

Relationale Datenbanken bieten auch die Möglichkeit, komplexe Datenabfragen durchzuführen, um spezifische Daten zu finden und zu analysieren. Mithilfe von SQL-Abfragen können Benutzer Daten einfach filtern, sortieren und gruppieren, um schnell Informationen zu finden und Trends zu erkennen.

Darüber hinaus bieten relationale Datenbanken verschiedene Funktionen zur Datensicherheit, wie beispielsweise die Einschränkung von Zugriffsrechten auf Tabellen und Spalten. Dies trägt dazu bei, dass sensible Daten nur von autorisierten Personen eingesehen und bearbeitet werden können, um Datenschutz- und Compliance-Anforderungen zu erfüllen.


![Entityrelations-Diagramm](entityrelationsdiagram.png)

## Task 3
```{r}
Zulassungen_aller_Fahrzeuge <- read_csv2("./Data/Zulassungen/Zulassungen_alle_Fahrzeuge.csv")
types = sapply(Zulassungen_aller_Fahrzeuge, typeof)
attributes = names(Zulassungen_aller_Fahrzeuge)
datatypes = data.frame(attributes, types)
colnames(datatypes) <- c("Attribut", "Datentyp")
kable(datatypes, row.names = FALSE, caption="Attribute der Datentypen", format="simple")
```





## Task 4
```{r, message=FALSE}
if(!require("install.load")){
  install.packages("install.load")
}
library(install.load)

install_load("readr", "dplyr", "ggplot2", "plotly", "knitr", "purrr", "moments","tidyverse", "scales")
```



Der Datensatz wird eingelesen.
```{r}
fehleranalyse <- read.csv("Fahrzeuge_OEM1_Typ11_Fehleranalyse.csv")

```

Aus ID_Fahrzeug wird eine Zählvariable namens ID erstellt (damit man daraus eine zeitliche Reihenfolge ableiten kann). 
```{r}
fehleranalyse <- fehleranalyse %>% mutate(ID = as.numeric(substr(ID_Fahrzeug, 9, nchar(ID_Fahrzeug))))
```

Um ein Modell erstellen zu können, müssen die Werte, die engine annehmen kann, in numerische Werte umgewandelt werden (sie werden Dummyvariablen zugeordnet).
```{r}
fehleranalyse$engine <- ifelse(fehleranalyse$engine == "small", 0, 
                    ifelse(fehleranalyse$engine == "medium", 1, 2))
```

###
Fehlerhaft_Fahrleistung wird ins Verhältnis zu den anderen Variablen gesetzt. X1 wird als Relikt des Zusammenführens der Datensätze nicht berücksichtigt. Die Datumsangaben werden dabei ebenfalls nicht berücksichtigt, eine zeitliche Einordung wird anhand der ID_Fahrzeug (jetzt: ID) gemacht; je höher die ID, desto später wurde es produziert. Die Herstellernummer wird weggelassen, da nur ein Hersteller (Hersteller 1) im Datensatz dazu existiert. Es bleiben engine (mit Dummyvariablen), Werksnummer, fuel, days und ID_Fahrzeug (umgewandelt zur ID)

```{r}
lm_fahrleistung <- lm(Fehlerhaft_Fahrleistung ~ engine + Werksnummer + fuel + days + ID, data = fehleranalyse )

```
Mit summary() kann man sich die wichtigsten Kennzahlen anzeigen lassen.
```{r}
summary(lm_fahrleistung)
```
Der Koeffizient für "engine" hat einen Wert von -4.713e+03 mit einem Standardfehler von 9.134e+01. Der t-Wert beträgt -51.596 und der p-Wert ist kleiner als 0,001, was bedeutet, dass der Koeffizient für "engine" signifikant von Null verschieden ist und somit einen wichtigen Beitrag zur Erklärung der abhängigen Variable leistet.

Der Koeffizient für "Werksnummer" hat einen Wert von 3.101e+01 mit einem Standardfehler von 5.371e+01. Der t-Wert beträgt 0.577 und der p-Wert ist größer als 0,05, was bedeutet, dass der Koeffizient für "Werksnummer" nicht signifikant von Null verschieden ist und somit keinen wichtigen Beitrag zur Erklärung der abhängigen Variable leistet.

Der Koeffizient für "fuel" hat einen Wert von 5.252e+03 mit einem Standardfehler von 1.827e+01. Der t-Wert beträgt 287.402 und der p-Wert ist kleiner als 0,001, was bedeutet, dass der Koeffizient für "fuel" signifikant von Null verschieden ist und somit einen wichtigen Beitrag zur Erklärung der abhängigen Variable leistet.

Der Koeffizient für "days" hat einen Wert von -5.686e-02 mit einem Standardfehler von 9.005e-02. Der t-Wert beträgt -0.631 und der p-Wert ist größer als 0,05, was bedeutet, dass der Koeffizient für "days" nicht signifikant von Null verschieden ist und somit keinen wichtigen Beitrag zur Erklärung der abhängigen Variable leistet.

Der Koeffizient für "ID" hat einen Wert von -2.059e-04 mit einem Standardfehler von 8.307e-05. Der t-Wert beträgt -2.478 und der p-Wert ist kleiner als 0,05, was bedeutet, dass der Koeffizient für "ID" signifikant von Null verschieden ist und somit einen wichtigen Beitrag zur Erklärung der abhängigen Variable leistet.

Die relevanten Werte sind somit die Koeffizienten für "engine", "fuel" und "ID", da sie signifikant von Null verschieden sind und somit einen Einfluss auf die abhängige Variable haben. Der Koeffizient für "Werksnummer" und "days" sind nicht signifikant, was bedeutet, dass sie keinen Einfluss auf die abhängige Variable haben, daher werden sie im nächsten Run eliminiert.

( Wertd die Zahlen aus, gehe dabei auf jeden Koeffizienten ein und bestimme dessen Wichtigkeit:)

```{r}
lm_fahrleistung2 <- lm(Fehlerhaft_Fahrleistung ~ engine + fuel + ID
                       , data = fehleranalyse )

```

```{r}
summary(lm_fahrleistung2)
```
###
Alle drei Variablen haben p-Werte kleiner als 0.05, was darauf hindeutet, dass sie alle statistisch signifikant sind und einen Beitrag zur Vorhersage von Fehlerhaft_Fahrleistung leisten.
fuel (T-Wert = 287.404) ist die am stärksten mit der abhängigen Variable Fehlerhaft_Fahrleistung verbundene Variable.
engine (T-Wert = -51.601) ist ebenfalls stark mit der abhängigen Variable verbunden, aber weniger als fuel.
ID (T-Wert = -2.787) hat die schwächste Verbindung mit der abhängigen Variable im Vergleich zu engine und fuel.

Es lässt sich ein kausaler Zusammenhang zwischen engine und fuel vermuten, da es logisch erscheint, dass größere Motoren mehr Treibstoff verbrauchen. 

Dies wird mit dem Pearson-Korrelationskoeffizienten überprüft.

###

```{r}
correlation_coefficient <- cor(fehleranalyse$fuel, fehleranalyse$engine)

# Ausgabe des Korrelationskoeffizienten
print(correlation_coefficient)
```

Ein Pearson-Korrelationskoeffizient von 0.818 zeigt eine starke positive Korrelation zwischen den beiden Variablen fuel und engine. Das bedeutet, dass wenn der Wert einer Variable tendenziell zunimmt, der Wert der anderen Variable ebenfalls tendenziell zunimmt: größere Motoren verbrauchen also wie vermutet mehr Treibstoff als kleinere.

Im vorherigen Durchgang wies fuel mit einem T-Wert von 287.404 die stärksten Verbundenheit mit Fehlerhaft_Fahrleistung auf, daher folgt ein Durchgang nur mit der ID und fuel als stärker eingehende der beiden abhängigen Variablen.

```{r}
lm_fahrleistung3 <- lm(Fehlerhaft_Fahrleistung ~ ID + fuel, data = fehleranalyse )

```

```{r}
summary(lm_fahrleistung3)
```
Variante ohne engine:

RSE: 11230
Adjusted R-squared: 0.4755
F-Statistik: 8.979e+04, p-Wert: < 2.2e-16

Variante mit engine: 

RSE: 11160
Adjusted R-squared: 0.4825
F-Statistik: 6.155e+04, p-Wert: < 2.2e-16

Ein niedrigerer RSE-Wert zeigt ein besseres Modell an. In diesem Fall hat die Variante mit engine (RSE: 11160) einen niedrigeren RSE-Wert als Variante ohne engine (RSE: 11230), was darauf hindeutet, dass Variante 2 besser ist.
Ein höherer Adjusted R-squared-Wert zeigt ein besseres Modell an. Variante mit enginge hat einen Adjusted R-squared-Wert von 0.4825, während Variante ohne engine einen Wert von 0.4755 hat. Daher ist Variante mit engine besser in Bezug auf die Anpassung an die Daten.Beide Modelle haben einen sehr niedrigen p-Wert (< 2.2e-16), was darauf hindeutet, dass die Modelle statistisch signifikant sind. In diesem Fall ist die F-Statistik allein nicht aussagekräftig genug, um die Modelle zu vergleichen. Insgesamt kann also festgestellt werden, dass das lineare Regressionsmodell mit diesen drei Parametern am geeignetsten ist, um einen Zusammenhang zu der Fahrleistung herzustellen.





Zusammenfassend deutet die Analyse darauf hin, dass das Modell eine gute Erklärungskraft für die abhängige Variable hat und die unabhängigen Variablen signifikante Beiträge zur Erklärung der Variation der abhängigen Variable liefern. Die Residuen deuten jedoch darauf hin, dass das Modell möglicherweise noch verbessert werden kann, dafür benötigte es ein komplizierteres Modell oder neue Daten.



Die Ergebnisse zeigen, dass alle drei unabhängigen Variablen (engine, fuel und ID) statistisch signifikant sind, da ihre p-Werte unter 0,05 liegen. Die Koeffizienten geben an, wie stark jede Variable das abhängige Ergebnis beeinflusst.

Der Multiple R-Quadrat-Wert (0,4825) zeigt, dass das Modell etwa 48,25% der Varianz in den Daten erklären kann. Der Adjusted R-Quadrat-Wert ist ebenfalls 0,4825, was darauf hindeutet, dass die Anzahl der unabhängigen Variablen in diesem Modell angemessen ist.

Der F-Statistik-Wert (6,155e+04) ist groß und der zugehörige p-Wert (< 2,2e-16) ist sehr klein, was bedeutet, dass das Modell insgesamt statistisch signifikant ist.

Das Modell ist statistisch signifikant und erklärt einen angemessenen Anteil der Varianz in den Daten. Dennoch ist die Streuung der Residuen relativ groß, was darauf hindeutet, dass das Modell möglicherweise nicht für alle Fälle perfekte Vorhersagen trifft. Es könnte hilfreich sein, weitere Variablen in das Modell aufzunehmen oder eine andere Modellierungstechnik auszuprobieren, um die Vorhersagegenauigkeit zu erhöhen.

Die ID gibt an, wann das Auto gefertigt wurde. Je höher desto, desto geringer die Fahrleistung, bei der das Auto fehlerhaft wurde. Es lässt sich also ableiten, dass die Werke mit der Zeit schlechter gearbeitet haben könnten. Hier sollten regelmäßige Wartungs- und Qualitätskontrollarbeiten stattfinden. Je  größer die engine, desto kleiner ist Fehlerhaft_Fahrleistung und damit das wünschenswerte Ergebnis. Es ist möglich, dass Autos mit größeren Motoren eher für lange Strecken und Autos mit kleineren Motoren eher für kurze Strecken in der Innenstadt benutzt werden oder Käufer größerer Motoren zu einem riskanteren Fahrstil neigen, dies sollte mit Umfragen weiter bestimmt werden, um gesicherte Aussagen treffen zu können. Der Hersteller sollte allerdings für größere Motoren die Garantiezeit reduzieren, wenn es um Profitmaximierung geht. Für fuel gilt, dass ein höherer Treibstoffverbrauch eine längere Lebenszeit bedeutet. Hier sollte weiter untersucht werden, ob die Motoren möglicherweise zulasten der Lebensdauer optiminiert wurden.

